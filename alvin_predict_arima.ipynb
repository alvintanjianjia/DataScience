{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,to_timestamp,concat,lit,year,month,hour,to_date,weekofyear,date_format,when,rank,collect_list,udf,explode\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType, DoubleType,FloatType,IntegerType,ArrayType,StructField,StructType\n",
    "from pyspark.sql import SparkSession\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "from datetime import datetime\n",
    "from dateutil import relativedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import stldecompose\n",
    "from stldecompose.forecast_funcs import drift,mean\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import *\n",
    "from matplotlib import pyplot\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "import numpy\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "%autosave 0\n",
    "\n",
    "# Initialize spark session\n",
    "spark = SparkSession.builder.appName(\"prediction_4g_hw\").getOrCreate()\n",
    "\n",
    "pg_jdbc_conf = {'url':'jdbc:postgresql://10.55.56.46/myanmar?user=postgres&password=password123',\n",
    "               'daily_bh':'oss.nokia_4g_cell_master_ml_daily',\n",
    "               'weekly_bh':'oss.arima_test',\n",
    "                'weekly_timestamp':'oss.weekly_timestamp',\n",
    "               'predict':'oss.nokia_4g_monthly_prediction_arima'}\n",
    "\n",
    "\n",
    "cell_col = 'cell_name'\n",
    "week_number_col = 'week_number'\n",
    "years_col = 'years'\n",
    "measurement_col = 'prb'\n",
    "date_col = 'date'\n",
    "date_col1 = 'date1'\n",
    "\n",
    "\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.66)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\tmodel_fit = model.fit(disp=0)\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\terror = mean_squared_error(test, predictions)\n",
    "\treturn error\n",
    " \n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype('float32')\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(dataset, order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    "                    print('ARIMA%s MSE=%.3f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    "    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg\n",
    "\n",
    "\n",
    "def get_predictions(df,steps,prediction_period):\n",
    "    try:\n",
    "        size = int(len(df) * 0.66)\n",
    "        train, test = df[0:size], df[size:len(df)]\n",
    "        # load dataset\n",
    "        # evaluate parameters\n",
    "        p_values = [0, 1, 2]\n",
    "        d_values = range(0, 3)\n",
    "        q_values = range(0, 5)\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        best_cfg = evaluate_models(train.values, p_values, d_values, q_values)\n",
    "\n",
    "        X = df.values\n",
    "        history = [x for x in df.values]\n",
    "        initial_length = len(history)\n",
    "        predictions = list()\n",
    "        for t in range(prediction_period):\n",
    "            if best_cfg == None:\n",
    "                history.append(history[-1])\n",
    "                predictions.append(history[-1])\n",
    "            else:\n",
    "            #model = ARIMA(history, order=(0,0,0))\n",
    "                model = ARIMA(history, order=best_cfg)\n",
    "                model_fit = model.fit()\n",
    "                output = model_fit.forecast(steps=steps)\n",
    "                yhat = output[0]\n",
    "                predictions.append(yhat)\n",
    "                #obs = test[t]\n",
    "                history.append(output[0][0])\n",
    "        result = []\n",
    "        for i in range(initial_length,len(history)):\n",
    "\n",
    "            result.append(float(history[i]))\n",
    "        return result\n",
    "    except:\n",
    "        return [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "            \n",
    "        \n",
    "\n",
    "def predict_arima_func(ts,predict_weeks=6):\n",
    "    \n",
    "#     return [pd.date_range(start=datetime.now(),periods=12,freq='M').map(lambda x:str(x.date())).tolist(),predict.tolist()]\n",
    "    result = get_predictions(ts,1,predict_weeks)\n",
    "#     for element in result:\n",
    "#         element = float(element)\n",
    "    \n",
    "    return [pd.date_range(start='2019-01-07',periods=6,freq='w').map(lambda x:str(x.date())).tolist(),result]\n",
    "# .map(lambda x: [float(e) for e in x])]\n",
    "   \n",
    "\n",
    "def predict_linear_func(ts,predict_months=12):\n",
    "    X = np.arange(ts.shape[0]).reshape(-1,1)\n",
    "    y = ts.values\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,y)\n",
    "\n",
    "    predict = lr.predict(np.arange(X[-1]+1,X[-1]+predict_months+1).reshape(-1,1))  \n",
    "    return [pd.date_range(start=datetime.now(),periods=12,freq='M').map(lambda x:str(x.date())).tolist(),predict.tolist()]\n",
    "\n",
    "\n",
    "def predict_py(years,week_number,prb):\n",
    "    \n",
    "    df = pd.DataFrame([week_number,years,prb])\n",
    "    df = df.T\n",
    "    df = df.rename(columns={0:'week',1:'year',2:'prb'})\n",
    "    df = df.sort_values(by=['year','week'])\n",
    "    df = df.set_index('week')\n",
    "    \n",
    "    return predict_linear_func(df.iloc[:,1])\n",
    "\n",
    "def predict_arima(cell_name,date, prb):\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(prb,index=date,columns=['prb'])\n",
    "    df.index = df.index.map(pd.to_datetime)\n",
    "    df = df.sort_index()\n",
    "    \n",
    "#     with open('error_cell.txt','a') as f:\n",
    "        \n",
    "#         f.write('\\n')\n",
    "#         f.write(cell_name)\n",
    "#     df.to_pickle('error-cell.pkl')\n",
    "    df_return = predict_arima_func(df.iloc[:,0])\n",
    "#     if len(df_return) == 0:\n",
    "#         return [[pd.date_range(start=datetime.now(),periods=12,freq='M').map(lambda x:str(x.date())).tolist()],[0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "#     else:\n",
    "    return predict_arima_func(df.iloc[:,0])\n",
    "    \n",
    "# UDF creation\n",
    "udf_predict_py = udf(predict_py,ArrayType(ArrayType(StringType())))\n",
    "udf_predict_arima = udf(predict_arima,ArrayType(ArrayType(StringType())))\n",
    "\n",
    "zip_ = udf(\n",
    "  lambda x, y: list(zip(x, y)),\n",
    "  ArrayType(StructType([\n",
    "      # Adjust types to reflect data types\n",
    "      StructField(\"date\", StringType()),\n",
    "      StructField(\"predict_prb\", StringType())\n",
    "  ]))\n",
    ")\n",
    "\n",
    "# zip_ = udf(\n",
    "#   lambda x, y: list(zip(x, y)),\n",
    "#   ArrayType(StructType([\n",
    "#       Adjust types to reflect data types\n",
    "#       StructField(\"date\", StringType()),\n",
    "#       StructField(\"predict_prb\", StringType())\n",
    "#   ]))\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timestamp = spark.read.format('jdbc').options(url=pg_jdbc_conf['url'],\n",
    "                           dbtable=pg_jdbc_conf['weekly_timestamp']).load()\n",
    "df = spark.read.format('jdbc').options(url=pg_jdbc_conf['url'],\n",
    "                           dbtable=pg_jdbc_conf['weekly_bh']).load()\n",
    "\n",
    "df = df.join(df_timestamp, ['week_number'], \"outer\")\n",
    "df = df.withColumn('date',col('date').cast(StringType()))\n",
    "df = df.withColumn('date1', col('date'))\n",
    "\n",
    "# df.head(5)\n",
    "\n",
    "\n",
    "df = df.groupBy(cell_col).agg({week_number_col:'collect_list',\n",
    "                            years_col:'collect_list',\n",
    "                            date_col:'collect_list',\n",
    "                            date_col1:'collect_list',\n",
    "                            measurement_col:'collect_list'})\n",
    "\n",
    "df = df.withColumnRenamed('collect_list({})'.format(measurement_col),measurement_col).withColumnRenamed('collect_list({})'.format(week_number_col),week_number_col).\\\n",
    "    withColumnRenamed('collect_list({})'.format(years_col),years_col)\n",
    "\n",
    "\n",
    "df = df.withColumnRenamed('collect_list({})'.format(date_col),date_col)\n",
    "df = df.withColumnRenamed('collect_list({})'.format(date_col1),date_col1)\n",
    "\n",
    "# df = df.filter(col('cell_name') == 'BAL5396_22')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df.withColumn('predict_list',udf_predict_arima(col('cell_name'),col('date'), col('prb')))\n",
    "# df = df.withColumn('predict_list',udf_predict_py(col('years'),col('week_number'),col('prb')))\n",
    "df = df.withColumn('date',col('predict_list')[0]).withColumn('predict_prb',col('predict_list')[1])\n",
    "df = df.select([cell_col,'date','predict_prb'])\n",
    "\n",
    "df = df.withColumn('temp',zip_(col('date'),col('predict_prb')))\n",
    "df = df.withColumn('temp',explode('temp'))\n",
    "df = df.select(cell_col,col('temp.date'),col('temp.predict_prb'))\n",
    "\n",
    "\n",
    "df = df.withColumn('date',to_date(col('date'))).withColumn('predict_prb',col('predict_prb').cast(FloatType()))\n",
    "df = df.select('cell_name','predict_prb')\n",
    "\n",
    "df.write.format('jdbc').options(url=pg_jdbc_conf['url'],\n",
    "                           dbtable='{}'.format(pg_jdbc_conf['predict'])).mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "| cell_name|predict_prb|\n",
      "+----------+-----------+\n",
      "|BAL5008_23|   3.160381|\n",
      "|BAL5008_23|  2.9987497|\n",
      "|BAL5008_23|  2.9311094|\n",
      "|BAL5008_23|   2.902451|\n",
      "|BAL5008_23|  2.8901658|\n",
      "|BAL5008_23|  2.8848317|\n",
      "+----------+-----------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cell = pd.read_pickle('error-cell.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMANone MSE=inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['2019-01-13',\n",
       "  '2019-01-20',\n",
       "  '2019-01-27',\n",
       "  '2019-02-03',\n",
       "  '2019-02-10',\n",
       "  '2019-02-17'],\n",
       " [12.403666496276855,\n",
       "  12.403666496276855,\n",
       "  12.403666496276855,\n",
       "  12.403666496276855,\n",
       "  12.403666496276855,\n",
       "  12.403666496276855]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_arima_func(error_cell.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
